\chapter{روش انجام پروژه}
\section{مقدمه}

برای اجرای این پروژه راه‌های متفاوتی مورد بررسی قرار گرفته‌شد تا بتوان آنها را روی پهپاد پیاده‌سازی کرد. نتیجه نهایی پیاده سازی ۳ شبکه کانولوشن
به صورت پی در پی است. شبکه اول برای آشکارسازی موقعیت کف دست است. بدین صورت که هر فریم گرفته‌شده از دوربین پهپاد به ورودی مدل داده می‌شود و پس از پردازش آن خروجی یک ماتریس ۲۵۶*۲۵۶*۳ است که جعبه محدودکننده 
دست را شامل می‌شود. پس از آن، این ماتریس به مدل دوم به عنوان ورودی داده می‌شود، در این مدل جعبه مرزی برش خورده دست به صورت یک ماتریس گرفته‌شده و پس از پردازش، خروجی مدل برابر ۲۱ نقطه 
سه بعدی عطف دست و شاخص دست(راست یا چپ) است.  در ادامه مدل سوم به عنوان ورودی، یک ماتریس ۲۱*۲ می‌گیرد که مختصات نقاط  طول و عرض هر نقطه عطف دست است
چرا که عمق تصویر با توجه به ژست‌های در نظر گرفته شده از اهمیت بالایی برخوردار نیست. و در خروجی پیش‌بینی می‌کند که کدام ژست دست مد نظر کاربر است. با توجه به این پروژه ۹ ژست 
گوناگون مدنظر قرار گرفته‌شده (کاربر می‌تواند ژست‌های جدیدی اضافه کند)، خروجی شبکه کانولوشن شامل ۱۰ کلاس 
کلاس است که ۹ کلاس برای ژست‌ها و کلاسی برای زمانی که هیچ کدام از ژست‌ها انتخاب نشده در نظر گرفته‌شده.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.7\textwidth]{gesture.png}
    \caption{تشخیص ژست دست با کمک نقاط کلیدی دست}
    % \label{test}
\end{figure}


\section{انتخاب ژست‌های دست متناسب با حرکت پهپاد}
انتخاب ژست‌های مناسب برای هر یک از حرکات پهپاد از اهمیت ویژه‌ای برخوردار است. چرا که ژست‌هایی که از لحاظ مفهومی به عملکرد پهپاد شبیه هستند راحت‌تر به خاطر سپرده شده و تجربه دلپذیرتری را در کاربر به وجود می‌آورند. 
ما برای این پروژه 9 ژست دست را در نظر گرفته‌ایم تا بتوان حرکات پایه پهپاد را با آنها انجام داد. این حرکات شامل: حرکت رو به جلو،  حرکت رو به عقب،حرکت به پایین، حرکت به بالا، حرکت به راست، حرکت به چپ، فرود آمدن، 
ایستادن در موقعیت کنونی و گرفتن عکس است که نمونه ژست دست آنها با توجه به حرکت پهپاد نشان داده شده است.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.7\textwidth]{gestures.png}
    \caption{نمونه‌ای از ژست‌های انتخاب‌شده در مجموعه داده‌ها}
\end{figure}

% \section{دیتاست}
% برای جمع آوری دیتاست مناسب پروژه، از آنجایی که ژست‌های دست را بر اساس عملکرد پهپاد تعیین کردیم تا استفاده از آنها برای کاربر مورد پسند باشند، لذا پیدا کردن دیتاست آماده ناممکن است. جمع‌آوری دیتاست مناسب و جامع از اهمیت 
% بالایی برخوردار است زیرا از آنجایی که مدل باید در زمان واقعی کار کند نمی‌توان از لایه‌های زیادی استفاده کرد. پس باید برای بالا بردن دقت مدل از موارد دیگری کمک گرفت، از جمله آنها می‌توان به پیش‌پردازش، پس‌پردازش و دیتاست مناسب اشاره کرد.
% \\
% از آنجایی که رویکردهای متفاوتی برای این پروژه پیاده‌سازی شد تا بتوان به بهترین راهکار برای مدلی با حجم کم و در عین حال جامع رسید، دیتاست‌های گوناگونی جمع آوری شد که هر یک از آنها ویژگی خاصی از تصویر را به عنوان داده‌ی 
% مورد نیاز جمع‌آوری می‌کردند. از جمله ورودی کل عکس به صورت پیکسل‌های رنگی، پیدا کردن دست و ذخیره موقعیت آن به صورت پیکسل‌های 256*256، پیدا کردن نقاط کلیدی دست و ذخیره موقعیت آنها
% در دیتاست که در نتیجه این گزینه بهترین راه ممکن بود برای ذخیره داده‌ها و اجرای پروژه در نظر گرفته‌شد.
% \\
% در این پروژه برای آنکه کاربر توانایی اضافه کردن ژست دست جدید را نیز داشته باشد، کدی پیاده‌سازی شد تا با باز شدن دوربین
%  و زدن یک حرف یا کلمه یکسان برای هر کلاس اطلاعات آن تصویر استخراج شده و در دیتاست ذخیره شوند. این امر هم نه تنها جمع‌آوری داده را راحت تر می‌کند، بلکه کاربر می‌تواند با زدن یک دکمه کلاس جدیدی را شکل دهد.


\section{دیتاست}
برای جمع‌آوری دیتاست مناسب پروژه، از آنجایی که ژست‌های دست بر اساس عملکرد پهپاد تعیین شدند تا استفاده از آنها برای کاربر مورد پسند باشد، پیدا کردن دیتاست آماده غیرممکن است. جمع‌آوری دیتاست جامع و مناسب از اهمیت
 بالایی برخوردار است زیرا مدل باید در زمان واقعی کار کند و نمی‌توان از لایه‌های زیادی استفاده کرد. بنابراین، برای افزایش دقت مدل باید از روش‌های دیگری نظیر پیش‌پردازش، پس‌پردازش و استفاده از دیتاست مناسب بهره گرفت.
\\
رویکردهای متفاوتی برای این پروژه پیاده‌سازی شدند تا بهترین راهکار برای مدلی با حجم کم و در عین حال جامع یافت شود. در نتیجه، دیتاست‌های گوناگونی جمع‌آوری شدند که هر یک از آنها ویژگی خاصی از تصویر
 را به عنوان داده‌ی مورد نیاز جمع‌آوری می‌کردند. این رویکردها شامل استفاده از ورودی کل عکس به صورت پیکسل‌های رنگی، پیدا کردن دست و ذخیره موقعیت آن به صورت پیکسل‌های $256 \times 256$ و پیدا کردن نقاط کلیدی دست و ذخیره موقعیت آنها در دیتاست بود. در نهایت، گزینه سوم به عنوان بهترین راه ممکن برای ذخیره داده‌ها و اجرای پروژه انتخاب شد.

برای این پروژه، به منظور امکان اضافه کردن ژست دست جدید توسط کاربر، کدی پیاده‌سازی شد که با باز شدن دوربین و زدن یک حرف 
یا کلمه یکسان برای هر کلاس، اطلاعات آن تصویر استخراج شده و در دیتاست ذخیره شود. این روش نه تنها جمع‌آوری داده را راحت‌تر می‌کند، بلکه به کاربر اجازه می‌دهد با زدن یک دکمه، کلاس جدیدی را ایجاد کند.


\section{اهمیت ژست دست}
هنگام صحبت کردن، افراد از ژست‌ها استفاده می‌کنند. ژست‌ها جزء اساسی زبان هستند که اطلاعات معنادار و منحصر به فردی را منتقل می‌کنند. این حرکات به گوینده کمک می‌کنند تا اهداف خود
 را بهتر منعکس کند و نقش‌های مهمی در ارتباط، یادگیری و درک ایفا می‌کنند، هم برای افرادی که آنها را مشاهده می‌کنند و هم برای کسانی که آن‌ها را انجام می‌دهند.
\\
به حرکات خود به خودی دست که در ریتم گفتار ایجاد می‌شوند، حرکات هم‌گفتاری \LTRfootnote{Co-Speech Gestures} گفته می‌شود. مردم از تمامی فرهنگ‌ها و پیشینه‌های زبانی شناخته شده برای ارتباط بهتر از حرکات هم‌گفتاری استفاده می‌کنند. حتی نوزادان قبل از بیان اولین کلمات خود، از انواع ژست‌ها استفاده می‌کنند. دست‌ها به ما کمک می‌کنند صحبت کنیم، فکر کنیم و به خاطر بسپاریم، گاهی اوقات دانشی را که هنوز
 نمی‌توان به زبان آورد، آشکار می‌کنند. به طوری که می‌توان گفت ژست‌ها اغلب به عنوان زبان گفتاری ثانویه در نظر گرفته می‌شوند \cite{clough2020role}.
\\
ژست‌ها به‌ویژه زمانی مؤثر هستند که مزیتی نسبت به کلمات داشته باشند \cite{kang2016hands}. توانایی درک شکل و حرکت دست‌ها می‌تواند یک
 جزء حیاتی در بهبود تجربه کاربر \LTRfootnote{User Experience} در حوزه‌ها و پلتفرم‌های مختلف فناوری باشد. درک مفهوم ژست دست در زمان واقعی برای افراد به طور طبیعی وجود دارد، اما این کار زمانی که توسط بینایی کامپیوتری رخ دهد می‌تواند چالش‌برانگیز باشد. زیرا
دست‌ها اغلب خود یا یکدیگر را مسدود می‌کنند مانند انسداد انگشت، کف دست و حتی لرزش دست نیز می‌تواند مشکلاتی به وجود آورد \cite{zhang2020mediapipe}.


\section{کنترل پهپاد}
اکثر پهپادهای تجاری موجود در بازار یا دارای کنترلرهای ویژه طراحی شده هستند، یا از فرستنده‌های سیگنال اختصاصی و برنامه‌های نرم‌افزاری استفاده می‌کنند که روی
 دستگاه‌های دستی کاربران مانند تلفن‌های همراه یا تبلت‌ها اجرا می‌شوند. در هر دو حالت، کنترل‌کننده فرمان‌هایی را با اطلاعات دقیق از طریق کانال‌های بی‌سیم مانند وای‌فای یا بلوتوث ارسال می‌کند. 
\\
اخیراً محصولات تجاری معرفی شده‌اند که از حرکات دست به عنوان یک مکانیسم کنترل قابل اجرا استفاده می‌کنند. برای دریافت ژست‌ها، دو رویکرد اصلی وجود دارد:
\begin{itemize}
    \item \textbf{استفاده از دستکش‌های ویژه طراحی شده:} کنترل‌کننده بر روی دستکشی که توسط کاربران استفاده می‌شود نصب می‌گردد و در زمان واقعی انحراف، گام و چرخش دست را شناسایی می‌کند تا حرکات مربوط به پهپاد را تشخیص و ارسال کند. از جمله این محصولات می‌توان به \lr{Kd Interactive Aura Drone} و \lr{MenKind Motion Control Drone} اشاره کرد.
    \item \textbf{استفاده از بینایی کامپیوتر از طریق دوربین:} این دستگاه‌ها از دوربین نصب شده روی پهپاد استفاده می‌کنند تا بتوانند در لحظه تشخیص دهند که دست کاربر کجاست و در چه حالتی قرار دارد تا پهپاد را کنترل کنند. از جمله این محصولات می‌توان به \lr{DJI Spark Drone} اشاره کرد.
\end{itemize}


\section{ابزار‌ها و نرم افزار های مورد استفاده}
برای پیاده‌سازی این پروژه از ابزار‌ها، نرم‌افزار‌ها و کتابخانه‌های گوناگونی استفاده شده‌است که در ادامه به توضیح دقیق آنها می‌پردازیم. قابل ذکر است که از کتابخانه‌هایی از جمله \lr{Csv}، \lr{Copy}، \lr{Itertools} و \lr{Os} نیز در قسمت‌هایی از پروژه به‌کار برده‌شده است که به دلیل استفاده جزئی توضیح داده نشده‌اند.

% \subsection{زبان برنامه‌نویسی پایتون}

\subsection{کتابخانه \lr{TensorFlow}}
\lr{TensorFlow} یک کتابخانه نرم‌افزاری رایگان و منبع باز برای یادگیری ماشین و هوش مصنوعی است. این کتابخانه توسط گوگل برین توسعه داده‌شده و می‌تواند در طیف وسیعی 
از وظایف یادگیری ماشین مورد استفاده قرار گیرد. همچنین تمرکز ویژه‌ای بر آموزش و استنتاج شبکه‌های عصبی عمیق دارد. 
\\
\lr{TensorFlow} انعطاف‌پذیری بالا دارد. می‌تواند برای انواع مختلف مدل‌های یادگیری ماشین از جمله شبکه‌های عصبی پیچشی، شبکه‌های عصبی بازگشتی و شبکه‌های مولد متخاصم\LTRfootnote{Generative Adversarial Network} مورد استفاده قرار گیرد.
\lr{TensorFlow} قابلیت اجرای مدل‌ها بر روی پردازنده‌های چندگانه، پردازنده‌های گرافیکی\LTRfootnote{Graphics Processing Unit} و واحد پردازشی تنسو\LTRfootnote{Tensor Processing Unit} را دارد. همچنین به دلیل محبوبیت و پشتیبانی گسترده،
منابع آموزشی و کتابخانه‌های جانبی فراوانی برای آن وجود دارد. به طور کلی،\lr{TensorFlow}  یکی از ابزارهای قدرتمند و پرکاربرد در حوزه یادگیری ماشین و هوش مصنوعی است \cite{Introduc60:online}.


\subsection{کتابخانه \lr{Scikit-learn}}
\lr{Scikit-learn} که با نام‌های \lr{Scikits.learn} و \lr{Sklearn} نیز شناخته می‌شود یک کتابخانه یادگیری ماشین رایگان و منبع باز برای زبان برنامه‌نویسی پایتون است. این کتابخانه شامل الگوریتم‌های مختلفی برای طبقه‌بندی،
رگرسیون و خوشه‌بندی مانند ماشین‌های بردار پشتیبان، جنگل‌های تصادفی، تقویت گرادیان، \lr{K-means} و \lr{DBSCAN} می‌باشد. \lr{Scikit-learn} به طور ویژه برای تعامل با
کتابخانه‌های \lr{NumPy} و \lr{SciPy} طراحی شده است و ابزارهای متنوعی برای پیش‌پردازش داده‌ها، انتخاب و ارزیابی مدل‌ها و کاهش ابعاد فراهم می‌کند. این کتابخانه به کاربران کمک می‌کند تا به راحتی از آن در پروژه‌های 
یادگیری ماشین استفاده کنند. این کتابخانه به دلیل سادگی و کارایی خود در بین محققان و مهندسان داده بسیار محبوب است و امکانات وسیعی را برای توسعه و ارزیابی مدل‌های یادگیری ماشین فراهم می‌کند \cite{scikitle22:online}.

\subsection{رابط برنامه‌نویسی \lr{Keras}}
\lr{Keras} یک رابط برنامه‌نویسی\LTRfootnote{Application Programming Interface} یادگیری عمیق است که به زبان پایتون نوشته شده و می‌تواند بر روی \lr{JAX}،  \lr{TensorFlow}و \lr{PyTorch} اجرا شود. هدف اصلی \lr{Keras} کاهش پیچیدگی‌ها و بار شناختی توسعه‌دهندگان است، 
به طوری که آنها بتوانند روی بخش‌های حیاتی و مهم پروژه‌های یادگیری ماشین تمرکز کنند. این رابط برنامه‌نویسی با رابط کاربری ساده و کاربرپسند، امکان توسعه سریع مدل‌های پیچیده را فراهم
می‌کند. \lr{Keras} عملکرد بالایی دارد و توسط سازمان‌های بزرگی نظیر ناسا، یوتیوب و \lr{Waymo} برای تحلیل داده‌ها، بهبود الگوریتم‌های توصیه‌گر و توسعه سیستم‌های خودران مورد استفاده قرار 
می‌گیرد. این کتابخانه با مستندات جامع و پشتیبانی از جامعه کاربری بزرگ، به یکی از ابزارهای محبوب در حوزه یادگیری عمیق تبدیل شده‌است \cite{AboutKer57:online}.

% \subsection{کتابخانه‌های\lr{MediaPipe}}
% \lr{MediaPipe} مجموعه ای از کتابخانه ها و ابزارهایی است که از تکنیک‌های هوش مصنوعی و یادگیری ماشین در برنامه‌های خود استفاده می‌کند.
% این کتابخانه برای برنامه‌نویسان یادگیری ماشین از جمله محققان، دانشجویان و توسعه‌دهندگان نرم‌افزار، که برنامه‌های کاربردی یادگیری ماشین را پیاده‌سازی می‌کنند، نمونه‌های
% اولیه فناوری را طراحی می‌کند تا بتوان پروژه‌ها را تا حد امکان ساده کرد.
% برنامه‌هایی که داده‌های حسی مثل ویدیو و صدا را با نرخ فریم بالا پردازش می‌کند تا تجربه کاربر را بهتر کند. مراحل پردازش یا مدل‌های استنتاجی ممکن است دشوار باشد، چون 
% گاهی اتصال بین مراحل زیاد است. همچنین، توسعه برنامه برای پلتفرم‌ زمان‌بر است \cite{lugaresi2019mediapipe}. 
% \\
% \lr{Media Pipe} این چالش‌ها را با انتزاع و اتصال مدل‌های مختلف به یکدیگر در یک چارچوب مناسب حل می‌کند. با استفاده از \lr{MediaPipe}، می‌توان یک لوله پردازش را به صورت 
% گراف از اجزای مختلف، از جمله مدل‌های استنتاجی و عملکردهای پردازش رسانه‌ای، ساخت.
% همچنین این کتابخانه می‌تواند مطابق با نیازهای افراد خود سفارشی شود و در پلتفرم‌های مختلف توسعه پیدا کند.
% \\
% در مجموعه \lr{MediaPipe} نیز از کتابخانه‌های مختلفی برای پیاده‌سازی برنامه ها استفاده می‌شود. از جمله آنها می‌توان به \lr{TensorFlow}، \lr{PyTorch}، \lr{OpenCV}، \lr{CNTK} و \lr{MXNet} اشاره کرد \cite{harris2021applying}. 


\subsection{کتابخانه‌های \lr{MediaPipe}}
\lr{MediaPipe} مجموعه‌ای از کتابخانه‌ها و ابزارهایی است که از تکنیک‌های هوش مصنوعی و یادگیری ماشین در برنامه‌های خود استفاده می‌کند. این کتابخانه برای برنامه‌نویسان یادگیری ماشین از جمله محققان، دانشجویان و توسعه‌دهندگان
 نرم‌افزار، که برنامه‌های کاربردی یادگیری ماشین را پیاده‌سازی می‌کنند، نمونه‌های اولیه فناوری را طراحی می‌کند تا پروژه‌ها را تا حد امکان ساده کند.
\\
برنامه‌هایی که داده‌های حسی مانند ویدیو و صدا را با نرخ فریم بالا پردازش می‌کنند، به‌طور خاص برای بهبود تجربه کاربر
 طراحی شده‌اند. مراحل پردازش یا مدل‌های استنتاجی ممکن است پیچیده باشند، زیرا گاهی اتصال بین مراحل بسیار زیاد است. همچنین، توسعه برنامه برای پلتفرم‌های مختلف زمان‌بر است \cite{lugaresi2019mediapipe}. 
\\
\lr{MediaPipe} این چالش‌ها را با انتزاع و اتصال مدل‌های مختلف به یکدیگر در یک چارچوب مناسب حل می‌کند. با استفاده از \lr{MediaPipe}، می‌توان یک لوله پردازش را به صورت گراف از اجزای مختلف، از جمله مدل‌های استنتاجی و عملکردهای پردازش رسانه‌ای، ساخت. این کتابخانه همچنین قابل سفارشی‌سازی است و می‌تواند بر روی پلتفرم‌های مختلف توسعه یابد.
\\
در مجموعه \lr{MediaPipe} نیز از کتابخانه‌های مختلفی برای پیاده‌سازی برنامه‌ها استفاده می‌شود. از جمله آنها می‌توان به \lr{TensorFlow}، \lr{PyTorch}، \lr{OpenCV}، \lr{CNTK} و \lr{MXNet} اشاره کرد \cite{harris2021applying}.


\begin{figure}[h]
    \centering
    \includegraphics[width=0.85\textwidth]{mediapipe2.png}
    \caption{برخی کاربردهای کتابخانه \lr{MediaPipe}}
\end{figure}

\subsection{کتابخانه \lr{NumPy}}
\lr{NumPy} کتابخانه‌ای برای محاسبات علمی در پایتون است که آرایه‌های چندبعدی و توابعی برای عملیات سریع روی آرایه‌ها ارائه می‌دهد. در هسته‌ی \lr{NumPy}، شیء \lr{Ndarray} وجود 
دارد که آرایه‌های \lr{n}-بعدی با نوع داده‌ی همگن را در بر می‌گیرد و بسیاری از عملیات‌های ریاضی در آن انجام می‌شوند. این کتابخانه امکان انجام عملیات ریاضی پیشرفته و سایر 
عملیات‌ها روی تعداد زیادی داده را با کارایی بالا فراهم می‌کند، که با استفاده از دنباله‌های پایتون معمولی کارآمدی و کد کمتری دارند \cite{WhatisNu62:online}.

\subsection{کتابخانه \lr{Matplotlib}}
\lr{Matplotlib} یک کتابخانه متقابل پلتفرم\LTRfootnote{Cross-Platform}، برای تجسم داده‌ها و نمودارهای گرافیکی از جمله هیستوگرام، نمودارهای پراکنده و نمودار میله‌ای برای 
پایتون است. توسعه دهندگان همچنین می توانند از رابط‌های برنامه‌نویسی \lr{Matplotlib}  برای جاسازی نمودارها در برنامه های رابط کاربری گرافیکی استفاده کنند.
\\
یک اسکریپت \lr{matplotlib} پایتون به گونه ای ساختار یافته است که چند خط کد تنها چیزی است که در بیشتر موارد برای تولید نمودار داده بصری مورد نیاز است. لایه برنامه نویسی \lr{Matplotlib} دو رابط برنامه‌نویسی را پوشش می دهد:
\\
رابط برنامه‌نویسی \lr{Pyplot}، که سلسله مراتبی از اشیاء کد پایتون است که در بالای آن \lr{Matplotlib.Pyplot} قرار دارد. و رابط برنامه‌نویسی اشیاء گرا\LTRfootnote{Object Oriented} که می تواند 
با انعطاف پذیری بیشتری نسبت به \lr{Pyplot} مونتاژ شوند. این رابط برنامه‌نویسی دسترسی مستقیم به لایه‌های \lr{Backend Matplotlib} را فراهم می کند \cite{Introduc75:online}.

\subsection{کتابخانه \lr{OpenCV}}
\lr{OpenCV} یک کتابخانه متن باز برای بینایی کامپیوتری و یادگیری ماشین است که برای فراهم کردن زیرساخت مشترک برای برنامه‌های بینایی کامپیوتری و تسریع استفاده از ادراک ماشین در محصولات
تجاری طراحی شده است. این کتابخانه شامل بیش از 2500 الگوریتم بهینه‌سازی شده است که مجموعه جامعی از الگوریتم‌های کلاسیک و جدید بینایی کامپیوتری و یادگیری ماشین 
را فراهم می‌کند. \lr{OpenCV} به طور گسترده‌ای در شرکت‌ها، گروه‌های تحقیقاتی و نهادهای دولتی برای انجام پروژه‌های بینایی کامپیوتری و یادگیری ماشین استفاده می‌شود. این کتابخانه رابط‌های برنامه‌نویسی 
متعددی از جمله \lr{C++}، \lr{Python،} \lr{Java} و \lr{MATLAB} دارد که امکان انجام پروژه‌های بینایی با استفاده از زبان‌های برنامه‌نویسی مختلف را فراهم می‌کند \cite{AboutOpe4:online}.

\subsection{پهپاد \lr{DJI Tello}}
پهپاد \lr{DJI Tello} یک پهپاد کوادکوپتر کوچک و قابل برنامه‌ریزی است که برای مصارف آموزشی و تست پروتوتایپ توسط \lr{DJI} طراحی شده است. این پهپاد دارای ویژگی‌های ویژه‌ای مانند حرکات پایه‌ای کوادکوپتری و همچنین تکنولوژی 
کنترل پرواز \lr{DJI} و یک پردازنده \lr{Intel} بسیار قوی است. دوربین 5 مگاپیکسلی این پهپاد امکان ضبط ویدیو با کیفیت خوب را فراهم می‌کند. همچنین، پهپاد دارای یک سیستم موقعیت‌یابی بصری\LTRfootnote{Vision Positioning System} است که شامل 
یک دوربین و یک ماژول مادون قرمز 3 بعدی است و قادر است در فواصل 3.0 متر تا 30 متر ارتفاع کار کند .
\\
هسته پهپاد به عنوان مرکز پردازشی و کنترلی آن عمل می‌کند و از یک پردازنده \lr{Intel} قدرتمند پشتیبانی می‌کند. پهپاد \lr{DJI Tello} برای اجرای پروژه‌های هوش مصنوعی مانند تشخیص اشیاء روی پهپاد، از زبان 
برنامه‌نویسی پایتون و \lr{SDK} مربوطه پشتیبانی می‌کند. این \lr{SDK} به کاربران این امکان را می‌دهد که پروتوتایپ‌های پایه‌ای پروژه‌های خود را توسعه دهند و آن‌ها را بر روی پهپاد اجرا کنند .
\\
این پهپاد دارای باتری با جزئیات خاصیت مانند زمان پرواز و زمان شارژ است که می‌تواند از نظر عملکرد و ماندگاری باتری نسبت به پهپاد‌های دیگر مزیت داشته باشد. همچنین، پروژه‌های هوش مصنوعی که روی پهپاد \lr{DJI Tello} پیاده‌سازی می‌شوند، 
می‌توانند شامل تشخیص اشیاء، پیش‌بینی حرکت‌ها و یا حتی خودکارسازی فرآیندهای پروازی باشند. از جمله مدل‌های هوش مصنوعی که می‌تواند روی پهپاد \lr{DJI Tello} پیاده‌سازی شود، می‌توان به \lr{YOLOv3} اشاره کرد که برای تشخیص اشیاء با دقت بالا استفاده می‌شود \cite{bhujbal2022custom}.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{table.png}
    \caption{اطلاعات پهپاد \lr{DJI Tello}}
\end{figure}


\section{فلوچارت اجرای پروژه}
در این پروژه از ۳ مدل اصلی به صورت متوالی برای پیش‌بینی تعیین ژست دست استفاده شده‌است. این سه مدل شامل تشخیص دست، تشخیص نقاط کلیدی دست و در نهایت تعیین ژست دست است. پس از استفاده از این مدل‌های بینایی ماشین، دستور پیش‌بینی شده برای اجرا به پهپاد \lr{DJI Tello} فرستاده می‌شود.
\\
برای بهینه کردن روند این پروژه ماژول‌های گوناگونی از جمله محدود كننده جريان زمان واقعي، تشخيص به مستطيل، برش تصوير، نقاط عطف يه مستطيل و ارائه كننده حاشيه نويسي نیز پیاده‌سازی شده‌اند تا روند پیش‌بینی ژست دست را با سرعت و دقت بالاتری اجرا کنند.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\textwidth]{flowchart.png}
    \caption{فلوچارت پروژه}
\end{figure}



% \section{مدیاپایپ}
% برای پیاده سازی شبکه‌های تشخیص کف دست و پیدا کردن نقاط عطف دست از مدل‌های از قبل آموزش دیده\LTRfootnote{Pretrained} کتابخانه مدیاپایپ کمک گرفته‌شده است. مدیاپایپ  از یک خط لوله
% یادگیری ماشین متشکل از چندین مدل که با هم کار می‌کنند استفاده می‌کند: یک مدل تشخیص کف دست \LTRfootnote{Palm Detection Model}
% که تصویر را از ورودی می‌گیرد و  عکس محدوده دست را به عنوان خروجی دریافت می‌کند و یک مدل تشخیص نقاط عطف دست \LTRfootnote{Hand Landmark Model}
% که عکس دست را به عنوان ورودی گرفته و مختصات‌ 21 نقطه کلیدی بند‌های انگشتان دست را در ناحیه دست تشخیص می‌دهد.
% در عکس \ref{Chart} ماژول‌های مربوط به شناسایی نقاط کلیدی نشان داده‌شده که به تفکیک هر کدام را توضیح خواهیم داد.

% \begin{figure}[h]
%     \centering
%     \includegraphics[width=0.7\textwidth]{hand_chart.png}
%     \caption{نمودار \lr{MediaPipe} برای شناسایی نقاط کلیدی دست}
%     \label{chart}
% \end{figure}


% \subsection{تشخیص دست\protect\LTRfootnote{Hand Detection}}
% ماژول تشخیص کف دست که یکی از سه ماژول اصلی است، در دارای دقت متوسط ۷.۹۵ درصد است که این دقت بالا با استفاده از استراتژی‌های مختلف به دست آمده است. این ماژول به جای تشخیص دست، از یک مدل تشخیص کف دست استفاده می‌کند 
%  زیرا تشخیص محدوده‌های اجسام سفت و سخت مانند کف دست و مشت بسیار ساده‌تر از تشخیص دست‌ها با انگشتان مفصلی است. از الگوریتم سرکوب غیر حداکثری برای حذف تشخیص‌های تکراری و انتخاب 
% مرتبط‌ترین اشیاء شناسایی شده استفاده می‌شود که به کاهش مثبت کاذب و پیچیدگی محاسباتی کمک می‌کند. وظیفه اصلی این ماژول تشخیص دست در تصویر و محاسبه مکان دقیق دست است. این ماژول برای تشخیص دست در تصویر و 
% محاسبه مکان دقیق دست استفاده می‌شود و پس از تشخیص دست، مکان دقیق دست را به ماژول‌های بعدی ارسال می‌کند.
% \\
%  این ماژول قادر است به‌صورت دقیق و کارآمد موقعیت دست‌ها را شناسایی کند و نواحی مربوطه را برای پردازش‌های بعدی فراهم 
% کند. ورودی این ماژول شامل تصویر یا فریم ویدیو و پارامترهای تنظیمات است، در حالی که خروجی آن شامل مستطیل‌های محدوده دست‌ها، نمرات اطمینان و در صورت فعال بودن، دست غالب\LTRfootnote{Handedness} است. معماری این 
% ماژول شامل مراحل پیش پردازش\LTRfootnote{Preprocessing}، مدل تشخیص دست و پس پردازش \LTRfootnote{Postprocessing}  است که به ترتیب شامل نرمال‌سازی و تغییر اندازه تصویر، شبکه عصبی تشخیص دست و فیلترینگ و محاسبه نواحی مستطیلی دست‌ها می‌باشد.
% \\
% وظیفه اصلی ماژول شناسایی و محصور کردن دست‌ها در تصاویر و ویدیوها است که در کاربردهای مختلفی از جمله تشخیص حرکات دست، رابط‌های کاربری بدون لمس، تحلیل رفتار و ژست‌ها و کمک به افراد کم‌توان اهمیت دارد. این 
% ماژول به توسعه‌دهندگان این امکان را می‌دهد که به راحتی و با دقت بالا دست‌ها را در تصاویر و ویدیوها شناسایی کرده و از این اطلاعات برای پردازش‌های بعدی استفاده کنند.


\subsection{تشخیص دست\protect\LTRfootnote{Hand Detection}}
ماژول تشخیص کف دست، یکی از سه ماژول اصلی، با دقت متوسط ۷.۹۵ درصد عمل می‌کند که این دقت بالا با استفاده از استراتژی‌های مختلف به دست آمده است. این ماژول به جای تشخیص دست، 
از یک مدل تشخیص کف دست استفاده می‌کند زیرا تشخیص محدوده‌های اجسام سفت و سخت مانند کف دست و مشت بسیار ساده‌تر از تشخیص دست‌ها با انگشتان مفصلی است. از
 الگوریتم سرکوب غیر حداکثری برای حذف تشخیص‌های تکراری و انتخاب مرتبط‌ترین اشیاء شناسایی شده استفاده می‌شود که به کاهش مثبت کاذب و پیچیدگی محاسباتی کمک می‌کند. وظیفه اصلی این ماژول تشخیص دست در تصویر و محاسبه مکان دقیق دست است.

این ماژول قادر است به‌صورت دقیق و کارآمد موقعیت دست‌ها را شناسایی کند و نواحی مربوطه را برای
 پردازش‌های بعدی فراهم کند. ورودی این ماژول شامل تصویر یا فریم ویدیو و پارامترهای تنظیمات است، در حالی که خروجی آن شامل مستطیل‌های محدوده دست‌ها، نمرات اطمینان و در صورت فعال بودن، دست غالب\LTRfootnote{Handedness} است. معماری این ماژول شامل 
 مراحل پیش پردازش\LTRfootnote{Preprocessing}،مدل تشخیص دست و پس پردازش\LTRfootnote{Postprocessing} است که به ترتیب شامل نرمال‌سازی و تغییر اندازه تصویر، شبکه عصبی تشخیص دست و فیلترینگ و محاسبه نواحی مستطیلی دست‌ها می‌باشد.

وظیفه اصلی ماژول شناسایی و محصور کردن دست‌ها در تصاویر و ویدیوها است که در کاربردهای مختلفی از جمله تشخیص حرکات دست، رابط‌های کاربری بدون لمس، تحلیل رفتار و ژست‌ها و کمک به افراد کم‌توان
 اهمیت دارد. این ماژول به توسعه‌دهندگان این امکان را می‌دهد که به راحتی و با دقت بالا دست‌ها را در تصاویر و ویدیوها شناسایی کرده و از این اطلاعات برای پردازش‌های بعدی استفاده کنند.



\begin{figure}[h]
    \centering
    \includegraphics[width=0.7\textwidth]{mediapipe.png}
    \caption{خط لوله تشخیص دست}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.4\textwidth]{hand_detector.png}
    \caption{معماری مدل آشکارساز کف دست}
\end{figure}


\subsection{تشخیص نقاط عطف دست\protect\LTRfootnote{Hand Landmark}}
این ماژول که دیگر اصلی است،  یک ابزار قدرتمند برای تشخیص و ردیابی نقاط کلیدی دست است. این ماژول وظیفه تشخیص و محاسبه نقاط عطف دست را بر عهده دارد. ورودی این ماژول یک تصویر است که شامل دست یا دست‌هایی 
است که می‌خواهیم نقاط کلیدی آن‌ها را تشخیص دهیم. این تصویر باید از پیش‌پردازش شده و دارای ناحیه‌ای باشد که دست در آن قرار دارد  (جعبه مرزی) که توسط ماژول دیگری مانند تشخیص دست مشخص شده است.
\\
خروجی این ماژول شامل موقعیت سه‌بعدی ۲۱ نقطه کلیدی دست است که شامل مفاصل انگشتان و نوک انگشتان می‌باشد. این نقاط کلیدی به صورت مجموعه‌ای از مختصات (\lr{x, y, z}) ارائه می‌شود 
که موقعیت هر نقطه را در فضای سه‌بعدی نشان می‌دهد و \lr{z} نشان‌دهنده عمق نقطه نسبت به تصویر ورودی است.
\\
معماری این ماژول شامل استفاده از شبکه‌های عصبی عمیق برای تشخیص و ردیابی نقاط کلیدی دست است. این معماری شامل مراحل پیش‌پبردازش برای تغییر اندازه و نرمال‌سازی تصویر، تشخیص دست برای شناسایی ناحیه‌های دست، مدل 
نقاط عطف برای تشخیص دقیق نقاط کلیدی دست و پس‌ پبردازش برای تبدیل مختصات نقاط کلیدی به فرمت خروجی نهایی و اعمال اصلاحات لازم است.
\\
وظیفه اصلی این ماژول تشخیص و ردیابی دقیق نقاط کلیدی دست‌ها در تصاویر و ویدیوها است. این قابلیت می‌تواند در برنامه‌های مختلفی مانند واقعیت افزوده \LTRfootnote{Augmented Reality}، رابط‌های کاربری بدون لمس،
تحلیل حرکات، تشخیص حرکات دست در زبان اشاره و ... استفاده شود و توسعه‌دهندگان را قادر می‌سازد از این قابلیت‌های پیشرفته در برنامه‌های خود بهره ببرند \cite{zhang2020mediapipe}.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.7\textwidth]{landmark.png}
    \caption{معماری مدل نقطه عطف دست. این مدل دارای سه خروجی است که یک استخراج کننده ویژگی را به اشتراک می‌گذارند. هر سر توسط مجموعه داده های مربوطه که با همان رنگ مشخص شده اند آموزش داده می‌شود.}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{hand-landmarks.png}
    \caption{موقعیت ۲۱ نقطه کلیدی در ناحیه دست}
\end{figure}


\subsection{پیش‌بینی ژست دست}
برای پیش‌بینی ژست دست از مدل‌های گوناگونی استفاده شده است که معماری و مشخصات هر یک به تفکیک توضیح داده‌ شده‌اند. این معماری‌ها شامل شبكه پرسپترون چند لايه، شبكه عصبي كانولوشن، شبكه عصبي بازگشتي و شبكه‌هاي حافظه كوتاه مدت بلند مدت است. دلیل استفاده از این مدل‌ها حجم کم و در عین حال دقت بالای آنها است تا بتوان آنها را با یکدیگر قیاس و در نهایت بهترین مدل را برگزید. 
ورودی این مدل نقاط کلیدی دست و خروجی آن پس از پردازش شامل ۱۰ کلاس است. قابل ذکر است که کاربر توانایی اضافه کردن کلاس و در نتیجه ژست جدید را نیز در صورتی که پهپاد قابلیت انجام آن را داشته باشد دارد.


\subsection{محدود کننده جریان زمان واقعی\protect\LTRfootnote{Real Time Flow Limiter}}
ماژول محدود کننده جریان زمان واقعی وظیفه محدود کردن جریان پردازش به سرعت زمان واقعی را بر عهده دارد. این ماژول امکان کنترل پردازش داده‌ها را به صورت کارآمد و در زمان واقعی فراهم می‌کند، بدون ایجاد تأخیر یا بار اضافی 
بر سیستم. ورودی‌های این ماژول شامل جریان‌های بسته\LTRfootnote{Packet Streams} و مهر زمان‌ها \LTRfootnote{Time Stamp} می‌شود و خروجی‌های آن شامل جریان‌های بسته با نرخ محدود\LTRfootnote{Rate-Limited Packet Streams} و اطلاعات مربوط به 
بسته‌های حذف شده ناشی از محدودیت نرخ پردازش است. معماری این ماژول شامل مراحل بافر ورودی \LTRfootnote{Input Buffering} ، تجزیه و تحلیل مهر زمانی\LTRfootnote{Timestamp Analysis}، الگوریتم محدود کردن نرخ\LTRfootnote{Rate Limiting Algorithm}  و
بافر خروجی\LTRfootnote{Output Buffering} است که به منظور محدود کردن نرخ جریان داده‌ها و انجام پردازش در زمان واقعی طراحی شده است. این ماژول کمک می‌کند تا بار پردازش کاهش یابد، تأخیر کاهش یابد، کیفیت خدمات حفظ شود و منابع محاسباتی بهینه‌سازی شوند \cite{zhang2020mediapipe}.


\subsection{تشخیص به مستطیل\protect\LTRfootnote{Detection To Rectangle}}
این ماژول وظیفه تبدیل نتایج تشخیص اشیاء به مستطیل‌های محدودکننده دست دارد. این ماژول ورودی‌هایی مانند تشخیص پروتوی\LTRfootnote{Detection Proto} و فریم تصویر\LTRfootnote{Image Frame} را دریافت کرده و مستطیل‌های محدودکننده را به صورت 
نرمال‌سازی شده و یا مطلق برای نواحی تشخیص داده شده تولید می‌کند. معماری این ماژول شامل مراحل  پیش‌پردازش، تبدیل تشخیص\LTRfootnote{Detection Conversion} و پس‌پردازش است. وظیفه اصلی این ماژول تبدیل نتایج تشخیص به 
مستطیل‌های محدودکننده است که در کاربردهای مختلف مانند تشخیص و ردیابی چهره، تشخیص دست، امنیتی و واقعیت افزوده کاربرد دارد \cite{zhang2020mediapipe}.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.55\textwidth]{bounding_box.jpeg}
    \caption{پیدا کردن مستطیل حاوی دست}
\end{figure}

\subsection{برش تصویر \protect\LTRfootnote{Image Cropping}}
ماژول برش تصویر برای برش و استخراج ناحیه‌های مورد نظر از تصاویر استفاده می‌شود. این ماژول ورودی‌هایی مانند تصویر اصلی و جعبه مرزی\LTRfootnote{Bounding Box} یا مختصات برش را می‌پذیرد و تصویر برش‌خورده حاوی ناحیه مورد 
نظر را تولید می‌کند. معماری این ماژول شامل مراحل پیش‌پردازش، عملیات برش\LTRfootnote{Cropping Operation}  و پس‌ پردازش  می‌باشد. وظیفه اصلی این ماژول برش دقیق ناحیه‌های مورد نظر از تصویر اصلی است که در کاربردهای 
مختلفی مانند پیش‌پردازش برای تشخیص چهره یا دست، تحلیل تصاویر پزشکی، واقعیت افزوده و پردازش تصویر در کاربردهای امنیتی مورد استفاده قرار می‌گیرد. این ماژول به 
توسعه‌دهندگان این امکان را می‌دهد که ناحیه‌های خاصی از تصاویر را به‌صورت دقیق و مؤثر استخراج کرده و برای پردازش‌های بعدی آماده کنند \cite{zhang2020mediapipe}.


\subsection{نقاط عطف یه مستطیل\protect\LTRfootnote{Landmarks To Rectangle}}
این ماژول برای تبدیل نقاط کلیدی به مستطیل‌های محدودکننده استفاده می‌شود. این ماژول وظیفه دقیق محصور کردن نقاط کلیدی یک شیء، مانند دست یا چهره، را بر عهده دارد. با استفاده از این مستطیل‌ها، می‌توان موقعیت دقیق‌تر اشیاء در 
تصویر را نمایش داد و از آنها به عنوان ورودی برای ماژول‌های بعدی در گراف استفاده کرد. این ماژول شامل مراحل پیش‌پردازش داده‌های ورودی، محاسبه مستطیل محدودکننده، نرمال‌سازی مختصات مستطیل‌ها و تولید خروجی نهایی 
می‌باشد. وظیفه اصلی این ماژول تبدیل نقاط کلیدی به مستطیل‌های محدودکننده دقیق است که در بسیاری از کاربردها اهمیت دارد، از جمله ردیابی اشیاء، تحلیل حرکات، پیش‌پردازش برای مدل‌های دیگر و افزایش دقت در پردازش تصویر \cite{zhang2020mediapipe}.


\subsection{ارائه کننده حاشیه نویسی\protect\LTRfootnote{Annotation Renderer}}
این ماژول برای نمایش گرافیکی نتایج پردازش‌های مختلف بر روی تصاویر یا ویدیوها استفاده می‌شود. این ماژول اطلاعات حاشیه‌نویسی شامل نقاط کلیدی، مستطیل‌های محدودکننده، خطوط، متن و سایر اشکال گرافیکی را به صورت 
بصری بر روی تصاویر نمایش می‌دهد. وظیفه اصلی این ماژول شامل نمایش بصری نقاط کلیدی، مستطیل‌های محدودکننده، خطوط و اتصالات، متن و توضیحات بر روی تصاویر یا ویدیوها است. این ماژول به توسعه‌دهندگان امکان 
می‌دهد تا به راحتی و به صورت بصری نتایج پردازش‌های خود را مشاهده کنند و از این طریق به بهبود و ارزیابی عملکرد مدل‌ها و الگوریتم‌های خود بپردازند \cite{zhang2020mediapipe}.


% \subsection{مزیت‌های استفاده از کتابخانه \lr{MediaPipe}}

\subsection{مدل‌های کلاس‌بندی برای تعیین ژست دست}

\subsection{شبکه پرسپترون چند لایه}
شبکه پرسپترون چند لایه \LTRfootnote{Multilayer Perceptron} نوعی شبکه عصبی مصنوعی است که از چندین لایه نورون تشکیل شده است. نورون‌ها در پرسپترون‌های چند لایه  معمولاً از
توابع فعال‌سازی غیرخطی \LTRfootnote{Nonlinear Activation Functions} استفاده می‌کنند که به شبکه اجازه می‌دهد الگوهای پیچیده در داده‌ها را بیاموزد .پرسپترون‌های چند لایه در 
یادگیری ماشین اهمیت بالایی دارند زیرا می‌توانند روابط غیرخطی در داده ها را یاد بگیرند و آنها را به مدل های قدرتمندی برای کارهایی مانند طبقه بندی، رگرسیون و تشخیص الگو تبدیل می‌کند. 
\\
پرسپترون چندلایه نوعی شبکه عصبی پیش‌خور\LTRfootnote{Feedforward} است که از نورون‌های کاملاً متصل با نوع غیرخطی تابع فعال‌سازی تشکیل شده است و  برای تشخیص داده‌هایی که به صورت خطی قابل تفکیک نیستند استفاده می‌شود.
\\
پرسپترون‌های چند لایه به طور گسترده در زمینه‌های مختلف از جمله تشخیص تصویر، پردازش زبان طبیعی و تشخیص گفتار و سایر موارد استفاده شده اند. انعطاف پذیری آنها در
معماری و توانایی تقریب هر عملکرد تحت شرایط خاص آنها را به یک بلوک اساسی در یادگیری عمیق و تحقیقات شبکه عصبی تبدیل می‌کند. 

\begin{figure}[h]
    \centering
    \includegraphics[width=0.6\textwidth]{MLP.png}
    \caption{نمونه ای از پرسپترون‌های چند لایه دارای دو لایه پنهان}
\end{figure}


\subsection{شبکه عصبی کانولوشنال}
شبکه عصبی کانولوشنال\LTRfootnote{Convolutional Neural Network} یک الگوریتم یادگیری عمیق است از جمله کاربرد‌های آن تشخیص اشیا مانند طبقه بندی، تشخیص و تقسیم بندی تصویر 
بسیار مهم است. بسیاری از برنامه‌های کاربردی مانند اتومبیل های خودران، دوربین های نظارتی و موارد دیگر از شبکه عصبی کانولوشنال استفاده می‌کنند.
\\
برخلاف مدل‌های سنتی یادگیری ماشینی مانند ماشین بردار پشتیبانی و درخت‌های تصمیم که نیاز به استخراج دستی ویژگی‌ها دارند، شبکه‌های عصبی کانولوشنال می‌توانند استخراج خودکار ویژگی‌ها را در مقیاس 
انجام دهند و آنها را کارآمد کند. این شبکه‌ها می‌توانند الگوها را از داده‌ها تشخیص دهند و ویژگی‌ها را بدون توجه به موقعیت آن‌ها، اعم از چرخش، مقیاس یا جابجایی تصویر استخراج کنند.
\\
معماری شبکه‌های عصبی کانولوشنال سعی می‌کنند ساختار نورون ها را در سیستم بینایی انسان متشکل از چندین لایه تقلید کند، جایی که هر یک مسئول تشخیص یک ویژگی خاص در داده ها است. 
همانطور که در تصویرببب نیز نشان داده شده است، شبکه عصبی کانولوشن از چندین لایه مانند لایه ورودی، لایه کانولوشن، لایه ادغام \LTRfootnote{Pooling} و لایه‌های کاملاً متصل تشکیل شده است.
\\
لایه کانولوشنال فیلترهایی را روی تصویر ورودی اعمال می‌کند تا ویژگی‌ها را استخراج کند، لایه ادغام ابعاد تصویر را کاهش می‌دهد تا محاسبات را سریع‌تر و کمتر کند، لایه کاملاً متصل پیش بینی نهایی را انجام می‌دهد. بدین صورت که شبکه فیلترهای بهینه را از طریق پس انتشار و نزول گرادیان می‌آموزد.


\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\textwidth]{CNN_arch.jpeg}
    \caption{نمونه معماری شبکه عصبی کانولوشنال}
\end{figure}

\subsection{شبکه عصبی بازگشتی}
شبکه عصبی بازگشتی\LTRfootnote{Recurrent Neural Network}  نوعی شبکه عصبی است که در آن خروجی مرحله قبل به عنوان ورودی به مرحله فعلی تغذیه می‌شود. در شبکه‌های عصبی سنتی، تمامی ورودی‌ها و خروجی‌ها مستقل از یکدیگر 
هستند. برای مثال در مواردی که پیش‌بینی مدل متکی به موارد قبلی است و نیاز است آنها را نیز مدنظر قرار دهد این شبکه بسیار کارآمد است. شبکه عصبی بازگشتی با کمک یک لایه پنهان این امکان را فراهم می‌کند. اصلی‌ترین و مهم‌ترین 
ویژگی شبکه عصبی بازگشتی حالت پنهان آن است که برخی از اطلاعات یک دنباله را به خاطر می‌سپارد. این حالت به عنوان حالت حافظه نیز شناخته می‌شود زیرا ورودی قبلی شبکه را به خاطر می‌آورد. و از پارامترهای یکسانی برای هر 
ورودی استفاده می‌کند زیرا وظیفه یکسانی را روی تمام ورودی‌ها یا لایه‌های پنهان برای تولید خروجی انجام می‌دهد. این بر خلاف سایر شبکه‌های عصبی، پیچیدگی پارامترها را کاهش می‌دهد.


\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{RNN.png}
    \caption{نمونه معماری شبکه عصبی بازگشتی}
\end{figure}

\subsection{شبکه‌های حافظه کوتاه مدت بلند مدت}
شبکه عصبی بازگشتی یک حالت پنهان دارد که در طول زمان منتقل می‌شود، که می‌تواند یادگیری وابستگی‌های طولانی مدت را برای شبکه دشوار کند. شبکه‌های حافظه کوتاه مدت بلند مدت این مشکل را با معرفی یک سلول حافظه، که محفظه 
ای است که می‌تواند اطلاعات را برای مدت طولانی نگهداری کند، برطرف می‌کند. شبکه‌های \LTRfootnote{Long Short-Term Memory } قادر به یادگیری وابستگی‌های طولانی‌مدت در داده‌های متوالی هستند، که آنها را برای کارهایی مانند ترجمه زبان، تشخیص گفتار و پیش‌بینی 
سری‌های زمانی مناسب می‌سازد. شبکه‌های حافظه کوتاه مدت بلند مدت همچنین می توانند در ترکیب با دیگر معماری‌های شبکه عصبی، مانند شبکه‌های عصبی کانولوشن برای تجزیه و تحلیل تصویر و ویدئو استفاده شوند.
\\
سلول حافظه توسط سه گیت کنترل می‌شود: گیت ورودی، دروازه فراموشی و گیت خروجی. این گیت‌ها تصمیم می‌گیرند که چه اطلاعاتی را به سلول حافظه اضافه، حذف کرده و از آن خروجی بگیرند. گیت ورودی کنترل می‌کند که چه اطلاعاتی 
به سلول حافظه اضافه می‌شود. دروازه فراموشی کنترل می‌کند که چه اطلاعاتی از سلول حافظه حذف می‌شود. و گیت خروجی کنترل می‌کند که چه اطلاعاتی از سلول حافظه خروجی می‌ شود.
این به شبکه‌های حافظه کوتاه مدت بلند مدت اجازه می‌دهد تا به‌طور انتخابی اطلاعات را در جریان جریان در شبکه حفظ یا کنار بگذارند، که به آنها امکان می‌دهد وابستگی‌های طولانی‌مدت را بیاموزند.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\textwidth]{LSTM.png}
    \caption{نمونه معماری شبکه‌ حافظه کوتاه مدت بلند مدت}
\end{figure}




\section{پیش‌پردازش}
برای ورود نقاط عطف دست به مدل تعیین ژست به ۲۱ مختصات طول و عرض نیاز داریم. خروجی مدل تعیین مختصات نقاط عطف دست برابر مختصات مطلق پیکسل‌ها نسبت به گوشه سمت 
چپ پایین تصویر است. این نقاط با توجه به اندازه عکس می‌توانند گسترده باشند برای مثال در یک عکس با اندازه ۲۰۴۸*۲۰۴۸ این اعداد از بین ۰ تا ۲۰۴۸ متغیر اند. 
اگر این مختصات را به صورت مستقیم به مدل تعیین ژست دست بدهیم دقت مدل برابر ۸۷ درصد خواهد بود که به میزان کافی مورد قبول نیست. برای بهبود آن باید پیش‌پردازش‌هایی بر روی داده ورودی انجام شود. 
\\
از جمله این پیش‌پردازش‌ها می‌توان به نسبی کردن و نرمال‌سازی داده‌ها اشاره کرد. برای این کار ابتدا باید یک مرجع واحد در نظر گرفت تا نقاط، نسبت به آن مشخص شوند. در این پروژه ما مرجع را نقطه 
مشخص شده روی مچ در نظر می‌گیریم. مختصات نقطه مرجع را برابر (0,0)  قرار می‌دهیم. سپس نسبت به آن و با توجه به فرمول زیر مختصات نقاط دیگر را به روز رسانی می‌کنیم.

% \begin{equation*}
%     X_new=\ \ (X-\ X_min)/(X_max-\ X_min)
% \end{equation*}
\[ X_{\text{\lr{rel}}} = X_{\text{\lr{ref}}} - X \]


پس از به نسبی کردن نقاط نسبت به مبدأ، آنها را با کمک فرمول زیر نرمال سازی می‌کنیم تا تمام طول و عرض نقاط به عددی میان صفر و یک به روز رسانی شوند.

\[ X_{\text{\lr{new}}} = \frac{X - X_{\text{\lr{min}}}}{X_{\text{\lr{max}}} - X_{\text{\lr{min}}}} \]
% \begin{equation*}
%     % X_new=\ \ (X-\ X_min)/(X_max-\ X_min)
% \end{equation*}

در انتها این این مختصات را به عنوان ورودی به شبکه تعیین ژست دست می‌دهیم. با توجه به اینکه معماری هیچ یک از مدل‌ها تغییر نکرد و تنها داده‌های مختصات به روز رسانی شدند، 
دقت نهایی مدل به ۹۷ درصد افزایش پیدا کرد و پیش‌پردازش تاثیر به‌سزایی در بهینه کردن پروژه داشت.


% \section{رأی‌گیری پنجره‌ای}
\section{پس‌پردازش}
با وجود اینکه دقت مدل پیاده‌سازی شده بالا است و عملکرد بسیار چشم‌گیری از خود نشان می‌دهد، در عین حال پیش‌بینی اشتباه مدل می‌تواند عواقب زیان‌باری را به ارمغان آورد، 
از تجربه ناپسند برای کاربر گرفته تا برخورد پهپاد به اجسام و هزینه مالی. لذا باید دقت انجام پروژه را از آنچه مدل پیش‌بینی می‌کند نیز بالاتر برد. برای این کار از رأی‌گیری پنجره‌ای 
استفاده کرده‌ایم. بدین صورت که متغیری را با توجه به \lr{FPS} دوربین در نظر می‌گیریم بدین صورت که هر چه \lr{FPS} دوربین پهپاد بیشتر باشد متغیر در نظر گرفته‌شده نیز بیشتر 
است، برای مثال در پروژه ما از آنجایی که دوربین پهپاد برابر 30 \lr{FPS} است ما این متغیر را ۱۰ قرار داده‌ایم.  سپس حد مناسبی را نیز بین صفر تا یک قرار می‌دهیم که ما در 
پروژه آن را برابر 0.7  قرار داده‌ایم. طبق این راه ما ۱۰ فریم متناوب گرفته‌شده از پهپاد را به مدل پیاده‌سازی شده می‌دهیم اما تنها در صورتی دستور پیش‌بینی شده را به پهپاد
پهپاد می‌دهیم که حد ممکن را بدست آورند. برای مثال اگر ۷ یا بیشتر از ۱۰ حرکت پیش بینی شده، دستور حرکت رو به جلو باشد آنگاه به پهپاد دستور داده می‌شود تا به جلو حرکت کند. 
در غیر این صورت اگر کمتر از ۷ عدد از فریم‌ها یک ژست دست را پیش‌بینی نکنند، پهپاد در حالت قبلی خود باقی می‌ماند و دستوری به آن داده نمی‌شود.


\section{جمع‌بندی}
در این فصل قسمت‌های مختلف پیاده‌سازی شده پروژه با جزئیات کامل توضیح داده شد. از جمله آنها نرم‌افزار‌ها و سخت‌افزارها، کتابخانه‌ها، پیش‌پردازش، پس‌پردازش و کد اصلی که شامل سه مدل به صورت پی در پی که دو تا از آنها با کمک کتابخانه \lr{MediaPipe} و دیگری یک کلاس‌بندی با ۹ حالت دست است بود.

